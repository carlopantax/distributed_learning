2025-06-10 09:49:21,314 - trainer_0 - INFO - Started training experiment: centralized_lamb_lr0.0075_wd0.05_batch_size16384_20250610_094921
2025-06-10 09:49:21,314 - trainer_0 - INFO - Log file: centralized_lamb_lr0.0075_wd0.05_batch_size16384/centralized_lamb_lr0.0075_wd0.05_batch_size16384_20250610_094921_rank0.log
2025-06-10 09:49:21,318 - trainer_0 - INFO - Training centralized on device: cpu
2025-06-10 09:49:21,318 - trainer_0 - INFO - Optimizer: LAMB, Epochs: 150, LR: 0.0075
2025-06-10 09:49:23,837 - trainer_0 - INFO - [DEBUG] Train dataset size: 40000 | Expected batches: 3
2025-06-10 09:49:23,851 - trainer_0 - INFO - Scaled LR using sqrt mode to: 0.08485281374238571
2025-06-10 09:49:23,851 - trainer_0 - INFO - Checking if there is any checkpoint. Resuming False, Checkpoint path: checkpoint.pth
